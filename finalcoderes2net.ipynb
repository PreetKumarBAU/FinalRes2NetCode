{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n    add, multiply\nfrom keras.layers import concatenate, core, Dropout\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.layers.core import Lambda\n#import keras.backend as K\n\n#%tensorflow_version 1.x\nimport os\nimport keras\nfrom keras.callbacks import TensorBoard\nimport tensorflow as tf\n#import keras.backend.tensorflow_backend as K\nimport keras.backend as K\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import CSVLogger\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T18:17:52.679443Z","iopub.execute_input":"2021-08-10T18:17:52.679813Z","iopub.status.idle":"2021-08-10T18:17:57.162300Z","shell.execute_reply.started":"2021-08-10T18:17:52.679736Z","shell.execute_reply":"2021-08-10T18:17:57.161258Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom glob import glob\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:57.163786Z","iopub.execute_input":"2021-08-10T18:17:57.164154Z","iopub.status.idle":"2021-08-10T18:17:58.054870Z","shell.execute_reply.started":"2021-08-10T18:17:57.164116Z","shell.execute_reply":"2021-08-10T18:17:58.053727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport numpy as np\nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport cv2\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nBackGround = [255, 255, 255]\nroad = [0, 0, 0]\n# COLOR_DICT = np.array([BackGround, road])\none = [128, 128, 128]\ntwo = [128, 0, 0]\nthree = [192, 192, 128]\nfour = [255, 69, 0]\nfive = [128, 64, 128]\nsix = [60, 40, 222]\nseven = [128, 128, 0]\neight = [192, 128, 128]\nnine = [64, 64, 128]\nten = [64, 0, 128]\neleven = [64, 64, 0]\ntwelve = [0, 128, 192]\nCOLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n\n\nclass data_preprocess:\n    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n                 test_path=None, save_path=None,\n                 img_rows=256, img_cols=256,\n                 flag_multi_class=False,\n                 num_classes = 2):\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.train_path = train_path\n        self.image_folder = image_folder\n        self.label_folder = label_folder\n        self.valid_path = valid_path\n        self.valid_image_folder = valid_image_folder\n        self.valid_label_folder = valid_label_folder\n        self.test_path = test_path\n        self.save_path = save_path\n        self.data_gen_args = dict(rotation_range=20,\n                                  width_shift_range=0.002,\n                                  shear_range=0.03,\n                                  zoom_range=0.005,\n                                  vertical_flip=True,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n        self.image_color_mode = \"rgb\"\n        self.label_color_mode = \"grayscale\"\n\n        self.flag_multi_class = flag_multi_class\n        self.num_class = num_classes\n        self.target_size = (256, 256)\n        self.img_type = 'png'\n\n    def adjustData(self, img, label):\n        if (self.flag_multi_class):\n            img = img / 255.\n            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n            new_label = np.zeros(label.shape + (self.num_class,))\n            for i in range(self.num_class):\n                new_label[label == i, i] = 1\n            label = new_label\n        elif (np.max(img) > 1):\n            #img = img / 255.\n            #label = label / 255.\n            #label[label >= 0.5] = 1\n            #label[label < 0.5] = 0\n            img2 =np.asarray(img)\n            label2 =np.asarray(label)\n            img2 =img2.astype('float32')\n            label2 =label2.astype('float32')\n            img2 /= 255.0\n            label2 /= 255.0\n            label2[label2 >= 0.5] = 1\n            label2[label2 < 0.5] = 0\n        return (img2, label2)\n\n    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n                       save_to_dir=None, seed=7):\n        '''\n        can generate image and label at the same time\n        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n        '''\n        image_datagen = ImageDataGenerator(**self.data_gen_args)\n        label_datagen = ImageDataGenerator(**self.data_gen_args)\n        image_generator = image_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=image_save_prefix,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=label_save_prefix,\n            seed=seed)\n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n\n    def testGenerator(self):\n        filenames = os.listdir(self.test_path)\n        for filename in filenames:\n            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n            img = img / 255.\n            img = trans.resize(img, self.target_size, mode='constant')\n            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n            img = np.reshape(img, (1,) + img.shape)\n            yield img\n\n    def validLoad(self, batch_size,seed=7):\n        image_datagen = ImageDataGenerator(rescale=0)\n        label_datagen = ImageDataGenerator(rescale=0)\n        image_generator = image_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)\n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n        # return imgs,labels\n\n    def saveResult(self, npyfile, size, name,threshold=80):\n        for i, item in enumerate(npyfile):\n            img = item\n            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n            if self.flag_multi_class:\n                for row in range(len(img)):\n                    for col in range(len(img[row])):\n                        num = np.argmax(img[row][col])\n                        img_std[row][col] = COLOR_DICT[num]\n            else:\n                for k in range(len(img)):\n                    for j in range(len(img[k])):\n                        num = img[k][j]\n                        if num < (threshold/255.0):\n                            img_std[k][j] = road\n                        else:\n                            img_std[k][j] = BackGround\n            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:58.057446Z","iopub.execute_input":"2021-08-10T18:17:58.057816Z","iopub.status.idle":"2021-08-10T18:17:58.609330Z","shell.execute_reply.started":"2021-08-10T18:17:58.057774Z","shell.execute_reply":"2021-08-10T18:17:58.608459Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"####  Metrics\n\nfrom keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\nimport numpy as np\ndef dice_coeff(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coeff(y_true, y_pred)\n    return loss\ndef iou_coeff(y_true, y_pred):\n    smooth=1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n    mvalue=(intersection+smooth)/(union+smooth)\n    return mvalue\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n\n    Only computes a batch-wise average of precision.\n\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\ndef recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\ndef ACL5(y_true, y_pred): \n\n\t#y_pred = K.cast(y_pred, dtype = 'float64')\n\n\tprint(K.int_shape(y_pred))\n\n\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n\n\tdelta_x = x[:,1:,:-2,:]**2\n\tdelta_y = y[:,:-2,1:,:]**2\n\tdelta_u = K.abs(delta_x + delta_y) \n\n\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n\tw = 1####\n\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n\n\n\tC_1 = np.ones((256, 256))\n\tC_2 = np.zeros((256, 256))\n\n\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n\n\tlambdaP = 5 # lambda parameter could be various.\n\t\n\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n\n\treturn loss\ndef ACL5_mod(y_true, y_pred): \n\n\t#y_pred = K.cast(y_pred, dtype = 'float64')\n\n\tprint(K.int_shape(y_pred))\n\n\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n\n\tdelta_x = x[:,1:,:-2,:]**2\n\tdelta_y = y[:,:-2,1:,:]**2\n\tdelta_u = K.abs(delta_x + delta_y) \n\n\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n\tw = 1####\n\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n\n\n\tC_1 = np.ones((256, 256))\n\tC_2 = np.zeros((256, 256))\n\n\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n\n\tlambdaP = 5 # lambda parameter could be various.\n\t\n\tloss =  lenth + lambdaP * ((region_in) + (region_out*1.4)) \n\n\treturn loss","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:58.611093Z","iopub.execute_input":"2021-08-10T18:17:58.611612Z","iopub.status.idle":"2021-08-10T18:17:58.636902Z","shell.execute_reply.started":"2021-08-10T18:17:58.611570Z","shell.execute_reply":"2021-08-10T18:17:58.636015Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beta = 0.25\nalpha = 0.25\ngamma = 2\nepsilon = 1e-5\nsmooth = 1\n\ndef tversky_index( y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n                1 - alpha) * false_pos + smooth)\n\ndef tversky_loss( y_true, y_pred):\n    return 1 - tversky_index(y_true, y_pred)\n\ndef focal_tversky( y_true, y_pred):\n    pt_1 = tversky_index(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1 - pt_1), gamma)\n\ndef dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:58.638440Z","iopub.execute_input":"2021-08-10T18:17:58.639033Z","iopub.status.idle":"2021-08-10T18:17:58.653152Z","shell.execute_reply.started":"2021-08-10T18:17:58.638994Z","shell.execute_reply":"2021-08-10T18:17:58.652216Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%env SM_FRAMEWORK=tf.keras","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:58.654612Z","iopub.execute_input":"2021-08-10T18:17:58.655069Z","iopub.status.idle":"2021-08-10T18:17:58.668529Z","shell.execute_reply.started":"2021-08-10T18:17:58.655029Z","shell.execute_reply":"2021-08-10T18:17:58.667587Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"env: SM_FRAMEWORK=tf.keras\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install segmentation_models\nimport segmentation_models\nfrom segmentation_models.losses import bce_jaccard_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:17:58.669936Z","iopub.execute_input":"2021-08-10T18:17:58.670236Z","iopub.status.idle":"2021-08-10T18:18:07.298060Z","shell.execute_reply.started":"2021-08-10T18:17:58.670211Z","shell.execute_reply":"2021-08-10T18:18:07.297156Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 1.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.7.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.2.0)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.6.3)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nSegmentation Models: using `tf.keras` framework.\n","output_type":"stream"}]},{"cell_type":"code","source":"def ACL5_bce_jaccard_loss(y_true, y_pred):\n    loss = ACL5(y_true, y_pred) + bce_jaccard_loss(y_true, y_pred)\n    return loss\n\n\ndef focal_tversky_bce_jaccard_loss(y_true, y_pred):\n    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n    return loss\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:18:07.300231Z","iopub.execute_input":"2021-08-10T18:18:07.300511Z","iopub.status.idle":"2021-08-10T18:18:07.308624Z","shell.execute_reply.started":"2021-08-10T18:18:07.300482Z","shell.execute_reply":"2021-08-10T18:18:07.307842Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add,average,concatenate\nfrom keras.layers.core import Lambda\nfrom keras.optimizers import *\nfrom keras.losses import binary_crossentropy\n#import tensorflow as tf\n#import keras.backend as K\n\n\n\nIMG_SIZE = 256\nh_heuns_method=0.5\n\ndef res_block(x, nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n    return res_path\ndef res_block2(x,y,nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n\n    res_path = average([y, res_path])#suma doble \n    return res_path\n\n\ndef encoder(x):\n    to_decoder = []\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n    main_path = BatchNormalization()(main_path)\n    main_path = Activation(activation='relu')(main_path)\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(main_path)\n\n    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1))(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    main_path = add([shortcut, hpath])#suma corta\n\n    to_decoder.append(main_path)\n\n\n    s1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2))(x)\n    s1 = BatchNormalization()(s1)\n\n    main_path = res_block2(main_path,s1, [128, 128], [(2, 2), (1, 1)]) \n    to_decoder.append(main_path)\n\n    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    s2 = Conv2D(filters=512, kernel_size=(1, 1), strides=(4, 4))(to_decoder[1])\n    s2 = BatchNormalization()(s2)\n\n    main_path = res_block2(main_path,s2, [512, 512], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    return to_decoder\n\n\ndef decoder(x, from_encoder):\n    \n    #main_path = UpSampling2D(size=(2, 2))(x)#32x32\n    main_path = Conv2DTranspose(512, [2, 2], strides=[2, 2])(x)\n    main_path1 = concatenate([main_path, from_encoder[3]], axis=3)\n    main_path = res_block(main_path1, [512, 512], [(1, 1), (1, 1)])\n\n    #main_path = UpSampling2D(size=(2, 2))(main_path)###64x64\n    #up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(main_path)\n    main_path = Conv2DTranspose(512, [2, 2], strides=[2, 2])(main_path)\n    main_path = concatenate([main_path, from_encoder[2]], axis=3)#\n    #u1 = UpSampling2D(size=(2, 2))(main_path1)#\n    u1 = Conv2DTranspose(256, [2, 2], strides=[2, 2])(main_path1)\n    u1 = Conv2D(256, kernel_size=(1, 1),strides=(1, 1))(u1)\n    u1 = BatchNormalization()(u1)\n    main_path = res_block2(main_path,u1, [256, 256], [(1, 1), (1, 1)])#\n\n    #main_path = UpSampling2D(size=(2, 2))(main_path)#128x128\n    main_path = Conv2DTranspose(128, [2, 2], strides=[2, 2])(main_path)\n    main_path2 = concatenate([main_path, from_encoder[1]], axis=3)#\n    main_path = res_block(main_path2, [128, 128], [(1, 1), (1, 1)])#\n\n    #main_path = UpSampling2D(size=(2, 2))(main_path)#256x256\n    main_path = Conv2DTranspose(64, [2, 2], strides=[2, 2])(main_path)\n    main_path = concatenate([main_path, from_encoder[0]], axis=3)#256x256\n\n    #u2 = UpSampling2D(size=(2,2))(main_path2)#\n    u2 = Conv2DTranspose(64, [2, 2], strides=[2, 2])(main_path2)\n    u2 = Conv2D(64, kernel_size=(1, 1),strides=(1, 1))(u2)#\n    u2 = BatchNormalization()(u2)\n    main_path = res_block2(main_path,u2, [64, 64], [(1, 1), (1, 1)])#256x256\n\n    return main_path\n\n\ndef res2unet(lrate=8.00E-05,pretrained_weights=None):\n    print(lrate)\n    input_size=(IMG_SIZE, IMG_SIZE, 3)\n    inputs = Input(shape=input_size)\n\n    to_decoder = encoder(inputs)\n\n    path = res_block(to_decoder[3], [1024, 1024], [(2, 2), (1, 1)])####bridge\n\n    path = decoder(path, from_encoder=to_decoder)\n\n\n    path = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(path)\n    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n    model = Model(inputs=inputs, outputs=path)\n    model.compile(optimizer=Adam(lr=lrate), loss=ACL5, metrics=[dice_loss,iou_coeff,precision,recall])\n    model.summary()\n    if (pretrained_weights):\n        model.load_weights(pretrained_weights)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:18:07.310962Z","iopub.execute_input":"2021-08-10T18:18:07.311250Z","iopub.status.idle":"2021-08-10T18:18:07.523656Z","shell.execute_reply.started":"2021-08-10T18:18:07.311226Z","shell.execute_reply":"2021-08-10T18:18:07.522687Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n\n#path to images\ntrain_path = \"../input/training/training\"\nimage_folder = \"images\"\nlabel_folder = \"label\"\nvalid_path =  \"../input/validation/Validation\"\nvalid_image_folder =\"images\"\nvalid_label_folder = \"label\"\nlog_filepath = './log'\nflag_multi_class = False\nnum_classes = 2\ndp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n                     flag_multi_class=flag_multi_class,\n                     num_classes=num_classes)\n\ntrain_data = dp.trainGenerator(batch_size=2)\nvalid_data = dp.validLoad(batch_size=1)\ntest_data = dp.testGenerator()\nmodel = res2unet(lrate=7.00E-05)\n\n\nmodel_checkpoint1 = keras.callbacks.ModelCheckpoint('Res2Net.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\ncsv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\nhistory = model.fit_generator(train_data,\n                              steps_per_epoch=1912,epochs=40,\n                              validation_steps=207,\n                              validation_data=valid_data,\n                              callbacks=[model_checkpoint1,csv_logger])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T18:18:07.525072Z","iopub.execute_input":"2021-08-10T18:18:07.525514Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"7e-05\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 256, 256, 64) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 256, 256, 64) 256         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n                                                                 lambda[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 256, 256, 64) 256         add[0][0]                        \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 128, 128, 128 73856       activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 128, 128, 128 8320        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 128, 128, 128 512         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 128, 128, 128 0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n                                                                 lambda_1[0][0]                   \n__________________________________________________________________________________________________\naverage (Average)               (None, 128, 128, 128 0           batch_normalization_2[0][0]      \n                                                                 add_1[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 128, 128, 128 512         average[0][0]                    \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 128, 128, 128 0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 64, 64, 256)  295168      activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 64, 64, 256)  33024       average[0][0]                    \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 64, 64, 256)  590080      activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 64, 64, 256)  1024        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 64, 64, 256)  0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 64, 64, 256)  0           batch_normalization_8[0][0]      \n                                                                 lambda_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        add_2[0][0]                      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 32, 32, 512)  1180160     activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 512)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 32, 32, 512)  131584      add_2[0][0]                      \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 32, 32, 512)  66048       average[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n                                                                 lambda_3[0][0]                   \n__________________________________________________________________________________________________\naverage_1 (Average)             (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 32, 32, 512)  2048        average_1[0][0]                  \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 1024) 4719616     activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 16, 16, 1024) 4096        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 16, 16, 1024) 0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 16, 16, 1024) 525312      average_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 16, 16, 1024) 9438208     activation_8[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 16, 16, 1024) 4096        conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 16, 16, 1024) 0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 1024) 0           batch_normalization_15[0][0]     \n                                                                 lambda_4[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           add_4[0][0]                      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 32, 1536) 0           up_sampling2d[0][0]              \n                                                                 average_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 32, 32, 1536) 6144        concatenate[0][0]                \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 32, 32, 1536) 0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 32, 32, 512)  7078400     activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 32, 32, 512)  2048        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 32, 32, 512)  0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 32, 32, 512)  786944      concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 32, 32, 512)  2359808     activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 32, 32, 512)  2048        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nlambda_5 (Lambda)               (None, 32, 32, 512)  0           conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 32, 32, 512)  0           batch_normalization_18[0][0]     \n                                                                 lambda_5[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 64, 64, 768)  0           up_sampling2d_1[0][0]            \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 64, 64, 768)  3072        concatenate_1[0][0]              \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 64, 64, 768)  0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 64, 64, 256)  1769728     activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 64, 64, 256)  1024        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 64, 64, 1536) 0           concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 64, 64, 256)  196864      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 64, 64, 256)  393472      up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 64, 64, 256)  1024        conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nlambda_6 (Lambda)               (None, 64, 64, 256)  0           conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 64, 64, 256)  1024        conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 64, 64, 256)  0           batch_normalization_22[0][0]     \n                                                                 lambda_6[0][0]                   \n__________________________________________________________________________________________________\naverage_2 (Average)             (None, 64, 64, 256)  0           batch_normalization_19[0][0]     \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           average_2[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 128, 128, 384 0           up_sampling2d_3[0][0]            \n                                                                 average[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 128, 128, 384 1536        concatenate_2[0][0]              \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 128, 128, 384 0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 128, 128, 128 442496      activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 128, 128, 128 512         conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 128, 128, 128 0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 128, 128, 128 49280       concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 128, 128, 128 147584      activation_14[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 128, 128, 128 512         conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nlambda_7 (Lambda)               (None, 128, 128, 128 0           conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 128, 128, 128 0           batch_normalization_25[0][0]     \n                                                                 lambda_7[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           add_7[0][0]                      \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_4[0][0]            \n                                                                 add[0][0]                        \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 256, 256, 192 768         concatenate_3[0][0]              \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 256, 256, 192 0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 256, 256, 64) 110656      activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 256, 256, 64) 256         conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 256, 256, 64) 0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)  (None, 256, 256, 384 0           concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 256, 256, 64) 12352       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 256, 256, 64) 36928       activation_16[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 256, 256, 64) 24640       up_sampling2d_5[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 256, 256, 64) 256         conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nlambda_8 (Lambda)               (None, 256, 256, 64) 0           conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 256, 256, 64) 256         conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 256, 256, 64) 0           batch_normalization_29[0][0]     \n                                                                 lambda_8[0][0]                   \n__________________________________________________________________________________________________\naverage_3 (Average)             (None, 256, 256, 64) 0           batch_normalization_26[0][0]     \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 256, 256, 2)  1154        average_3[0][0]                  \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 256, 256, 1)  3           conv2d_31[0][0]                  \n==================================================================================================\nTotal params: 33,651,397\nTrainable params: 33,630,021\nNon-trainable params: 21,376\n__________________________________________________________________________________________________\nFound 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\nEpoch 1/40\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n1912/1912 [==============================] - ETA: 0s - loss: 67039.4669 - dice_loss: 0.7593 - iou_coeff: 0.1538 - precision: 0.2185 - recall: 0.0864Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 256, 256, 1)\n1912/1912 [==============================] - 294s 148ms/step - loss: 67017.0801 - dice_loss: 0.7592 - iou_coeff: 0.1539 - precision: 0.2186 - recall: 0.0865 - val_loss: 4373.4771 - val_dice_loss: 0.9916 - val_iou_coeff: 0.0076 - val_precision: 0.0145 - val_recall: 4.9362e-04\n\nEpoch 00001: val_dice_loss improved from inf to 0.99160, saving model to Res2Net.hdf5\nEpoch 2/40\n1912/1912 [==============================] - 271s 142ms/step - loss: 5236.2449 - dice_loss: 0.3290 - iou_coeff: 0.5226 - precision: 0.8018 - recall: 0.6100 - val_loss: 2472.8745 - val_dice_loss: 0.3681 - val_iou_coeff: 0.5153 - val_precision: 0.7304 - val_recall: 0.5685\n\nEpoch 00002: val_dice_loss improved from 0.99160 to 0.36809, saving model to Res2Net.hdf5\nEpoch 3/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 4761.3734 - dice_loss: 0.2991 - iou_coeff: 0.5583 - precision: 0.8118 - recall: 0.6441 - val_loss: 2614.0168 - val_dice_loss: 0.4380 - val_iou_coeff: 0.4592 - val_precision: 0.6906 - val_recall: 0.4923\n\nEpoch 00003: val_dice_loss did not improve from 0.36809\nEpoch 4/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 4324.2147 - dice_loss: 0.2584 - iou_coeff: 0.6039 - precision: 0.8334 - recall: 0.6922 - val_loss: 2501.1731 - val_dice_loss: 0.3013 - val_iou_coeff: 0.5761 - val_precision: 0.7747 - val_recall: 0.6425\n\nEpoch 00004: val_dice_loss improved from 0.36809 to 0.30126, saving model to Res2Net.hdf5\nEpoch 5/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 4172.1023 - dice_loss: 0.2490 - iou_coeff: 0.6182 - precision: 0.8302 - recall: 0.7064 - val_loss: 2305.2854 - val_dice_loss: 0.2969 - val_iou_coeff: 0.5946 - val_precision: 0.6841 - val_recall: 0.6860\n\nEpoch 00005: val_dice_loss improved from 0.30126 to 0.29692, saving model to Res2Net.hdf5\nEpoch 6/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3960.4563 - dice_loss: 0.2283 - iou_coeff: 0.6424 - precision: 0.8443 - recall: 0.7290 - val_loss: 2074.2886 - val_dice_loss: 0.2761 - val_iou_coeff: 0.6169 - val_precision: 0.7795 - val_recall: 0.6499\n\nEpoch 00006: val_dice_loss improved from 0.29692 to 0.27610, saving model to Res2Net.hdf5\nEpoch 7/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3814.2320 - dice_loss: 0.2168 - iou_coeff: 0.6552 - precision: 0.8523 - recall: 0.7423 - val_loss: 2178.3750 - val_dice_loss: 0.3282 - val_iou_coeff: 0.5704 - val_precision: 0.7175 - val_recall: 0.5922\n\nEpoch 00007: val_dice_loss did not improve from 0.27610\nEpoch 8/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3683.5750 - dice_loss: 0.2104 - iou_coeff: 0.6650 - precision: 0.8533 - recall: 0.7514 - val_loss: 2390.9907 - val_dice_loss: 0.3359 - val_iou_coeff: 0.5609 - val_precision: 0.7614 - val_recall: 0.5935\n\nEpoch 00008: val_dice_loss did not improve from 0.27610\nEpoch 9/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3637.8408 - dice_loss: 0.2058 - iou_coeff: 0.6710 - precision: 0.8539 - recall: 0.7577 - val_loss: 2891.0015 - val_dice_loss: 0.5389 - val_iou_coeff: 0.3922 - val_precision: 0.5418 - val_recall: 0.3659\n\nEpoch 00009: val_dice_loss did not improve from 0.27610\nEpoch 10/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3580.4855 - dice_loss: 0.2010 - iou_coeff: 0.6773 - precision: 0.8594 - recall: 0.7621 - val_loss: 1963.5216 - val_dice_loss: 0.2449 - val_iou_coeff: 0.6412 - val_precision: 0.8124 - val_recall: 0.6730\n\nEpoch 00010: val_dice_loss improved from 0.27610 to 0.24494, saving model to Res2Net.hdf5\nEpoch 11/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3511.0196 - dice_loss: 0.1963 - iou_coeff: 0.6846 - precision: 0.8594 - recall: 0.7659 - val_loss: 2046.7495 - val_dice_loss: 0.2748 - val_iou_coeff: 0.6213 - val_precision: 0.7804 - val_recall: 0.6682\n\nEpoch 00011: val_dice_loss did not improve from 0.24494\nEpoch 12/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3445.7479 - dice_loss: 0.1880 - iou_coeff: 0.6946 - precision: 0.8591 - recall: 0.7786 - val_loss: 2033.0823 - val_dice_loss: 0.2593 - val_iou_coeff: 0.6293 - val_precision: 0.7702 - val_recall: 0.6727\n\nEpoch 00012: val_dice_loss did not improve from 0.24494\nEpoch 13/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3367.8909 - dice_loss: 0.1832 - iou_coeff: 0.7000 - precision: 0.8629 - recall: 0.7866 - val_loss: 2117.6135 - val_dice_loss: 0.2855 - val_iou_coeff: 0.6066 - val_precision: 0.8075 - val_recall: 0.6388\n\nEpoch 00013: val_dice_loss did not improve from 0.24494\nEpoch 14/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3338.5824 - dice_loss: 0.1836 - iou_coeff: 0.6999 - precision: 0.8640 - recall: 0.7844 - val_loss: 2106.1008 - val_dice_loss: 0.2360 - val_iou_coeff: 0.6500 - val_precision: 0.7590 - val_recall: 0.7320\n\nEpoch 00014: val_dice_loss improved from 0.24494 to 0.23599, saving model to Res2Net.hdf5\nEpoch 15/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3271.9414 - dice_loss: 0.1761 - iou_coeff: 0.7094 - precision: 0.8686 - recall: 0.7915 - val_loss: 2060.8442 - val_dice_loss: 0.2658 - val_iou_coeff: 0.6253 - val_precision: 0.7804 - val_recall: 0.6407\n\nEpoch 00015: val_dice_loss did not improve from 0.23599\nEpoch 16/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3219.4828 - dice_loss: 0.1747 - iou_coeff: 0.7129 - precision: 0.8703 - recall: 0.7955 - val_loss: 2101.9333 - val_dice_loss: 0.2259 - val_iou_coeff: 0.6561 - val_precision: 0.8023 - val_recall: 0.7477\n\nEpoch 00016: val_dice_loss improved from 0.23599 to 0.22589, saving model to Res2Net.hdf5\nEpoch 17/40\n1912/1912 [==============================] - 269s 141ms/step - loss: 3217.7257 - dice_loss: 0.1728 - iou_coeff: 0.7143 - precision: 0.8698 - recall: 0.7971 - val_loss: 1876.0140 - val_dice_loss: 0.2323 - val_iou_coeff: 0.6665 - val_precision: 0.7860 - val_recall: 0.6739\n\nEpoch 00017: val_dice_loss did not improve from 0.22589\nEpoch 18/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3102.8953 - dice_loss: 0.1628 - iou_coeff: 0.7268 - precision: 0.8753 - recall: 0.8096 - val_loss: 1896.2096 - val_dice_loss: 0.2865 - val_iou_coeff: 0.6181 - val_precision: 0.7632 - val_recall: 0.6319\n\nEpoch 00018: val_dice_loss did not improve from 0.22589\nEpoch 19/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3109.1829 - dice_loss: 0.1663 - iou_coeff: 0.7235 - precision: 0.8709 - recall: 0.8053 - val_loss: 1957.7727 - val_dice_loss: 0.2446 - val_iou_coeff: 0.6537 - val_precision: 0.7851 - val_recall: 0.6788\n\nEpoch 00019: val_dice_loss did not improve from 0.22589\nEpoch 20/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3076.2408 - dice_loss: 0.1642 - iou_coeff: 0.7270 - precision: 0.8742 - recall: 0.8086 - val_loss: 2181.6650 - val_dice_loss: 0.3149 - val_iou_coeff: 0.5862 - val_precision: 0.7501 - val_recall: 0.5740\n\nEpoch 00020: val_dice_loss did not improve from 0.22589\nEpoch 21/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3078.6735 - dice_loss: 0.1617 - iou_coeff: 0.7292 - precision: 0.8737 - recall: 0.8078 - val_loss: 1761.7441 - val_dice_loss: 0.2006 - val_iou_coeff: 0.6901 - val_precision: 0.8227 - val_recall: 0.7309\n\nEpoch 00021: val_dice_loss improved from 0.22589 to 0.20056, saving model to Res2Net.hdf5\nEpoch 22/40\n1912/1912 [==============================] - 270s 141ms/step - loss: 3033.9853 - dice_loss: 0.1575 - iou_coeff: 0.7348 - precision: 0.8795 - recall: 0.8137 - val_loss: 1970.2428 - val_dice_loss: 0.2507 - val_iou_coeff: 0.6479 - val_precision: 0.7715 - val_recall: 0.6940\n\nEpoch 00022: val_dice_loss did not improve from 0.20056\nEpoch 23/40\n 869/1912 [============>.................] - ETA: 2:24 - loss: 2999.8853 - dice_loss: 0.1600 - iou_coeff: 0.7319 - precision: 0.8801 - recall: 0.8110","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}